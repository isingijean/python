{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source = https://youtu.be/H0Ib_m-33pc?si=U4x0EKLsRt0wglZ2\n",
    "\n",
    "\n",
    "https://youtu.be/nCuPv3tf2Hg?si=jvHuYsjw9xugarG6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install required libraries\n",
    "# !pip install beautifulsoup4 pandas  # Install BeautifulSoup and pandas libraries if not already installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import requests  # For sending HTTP requests to fetch the webpage\n",
    "from bs4 import BeautifulSoup  # For parsing HTML content\n",
    "import pandas as pd  # For creating and manipulating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL of the website to scrape\n",
    "url = 'http://books.toscrape.com/'\n",
    "\n",
    "# Send an HTTP GET request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "# If not, raise an exception to stop the program\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse the HTML content of the webpage using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all book entries on the page\n",
    "# Each book is contained within an <article> tag with the class 'product_pod'\n",
    "books = soup.find_all('article', class_='product_pod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store book details\n",
    "book_data = []\n",
    "\n",
    "# Loop through each book entry to extract details\n",
    "for book in books:\n",
    "    # Extract the book title from the 'title' attribute of the <a> tag inside <h3>\n",
    "    title = book.h3.a['title']\n",
    "    \n",
    "    # Extract the book price from the <p> tag with class 'price_color'\n",
    "    price = book.find('p', class_='price_color').text\n",
    "    \n",
    "    # Extract the availability status from the <p> tag with class 'instock availability'\n",
    "    # Use .strip() to remove any leading or trailing whitespace\n",
    "    availability = book.find('p', class_='instock availability').text.strip()\n",
    "    # Extract the rating class (e.g., 'One', 'Two', 'Three', etc.)\n",
    "    rating_element = book.find('p', class_='star-rating')\n",
    "    rating = rating_element['class'][1] if rating_element else 'No rating'  # Safely handle missing ratings\n",
    "    \n",
    "    # Append the extracted details as a dictionary to the book_data list\n",
    "    book_data.append({'Title': title, 'Price': price, 'Availability': availability, 'Rating':rating_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "df = pd.DataFrame(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped Data:\n",
      "                                   Title    Price Availability Rating\n",
      "0                   A Light in the Attic  Â£51.77     In stock    Two\n",
      "1                     Tipping the Velvet  Â£53.74     In stock    Two\n",
      "2                             Soumission  Â£50.10     In stock    Two\n",
      "3                          Sharp Objects  Â£47.82     In stock    Two\n",
      "4  Sapiens: A Brief History of Humankind  Â£54.23     In stock    Two\n"
     ]
    }
   ],
   "source": [
    "# Print the scraped data to the console\n",
    "print(\"Scraped Data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "csv_file = 'books_data.csv'\n",
    "df.to_csv(csv_file, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
